{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AishwaryaN2203/Big-Data/blob/main/Analyzing_Social_Networks_using_GraphX_GraphFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iox_ufgbqDXa"
      },
      "source": [
        "<h1><center>Apache Spark GraphFrames</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qV6Grv7qIa9"
      },
      "source": [
        "Let's run GraphFrame code on Google Colab and see if it's faster than Databricks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd6t0uFzuR4X"
      },
      "source": [
        "\n",
        "### Installing Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6apGVff5h4ca"
      },
      "source": [
        "Install Dependencies:\n",
        "\n",
        "\n",
        "1.   Java 8\n",
        "2.   Apache Spark with hadoop and\n",
        "3.   Findspark (used to locate the spark in the system)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf spark-3.1.1-bin-hadoop3.2"
      ],
      "metadata": {
        "id": "CFdihR9S3lav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt7ZS1_wGgjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7cb98b6-79c6-4019-dbec-07f2b242be43"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q --show-progress http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "#!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark pyspark\n",
        "#!pip -q install findspark pyspark graphframes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3x0ZRLxjMVr"
      },
      "source": [
        "Set Environment Variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdOOq4twHN1K"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ACYMwhgHTYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecad3598-236a-434e-8ebe-85e342268e0e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UyTMRZMNc-P",
        "outputId": "f0ab4018-2188-4fa4-b2ce-617a27431030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyspark\n",
            "Version: 3.5.0\n",
            "Summary: Apache Spark Python API\n",
            "Home-page: https://github.com/apache/spark/tree/master/python\n",
            "Author: Spark Developers\n",
            "Author-email: dev@spark.apache.org\n",
            "License: http://www.apache.org/licenses/LICENSE-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: py4j\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing GraphFrames"
      ],
      "metadata": {
        "id": "h80DxqoaCbJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphframes"
      ],
      "metadata": {
        "id": "_PYxeVmcjt2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd1ffb7-6e78-45d3-c9e1-294bec70939c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphframes\n",
            "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.23.5)\n",
            "Collecting nose (from graphframes)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose, graphframes\n",
            "Successfully installed graphframes-0.6 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvBrk95ANPcA",
        "outputId": "fc572183-d59f-495c-a3f6-a38ef450fb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o \"/usr/local/lib/python3.10/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.3.2-s_2.11.jar\" https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.1-s_2.12/graphframes-0.8.2-spark3.1-s_2.12.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImOiBbPIPRYI",
        "outputId": "e84ff2a1-8e62-4932-d313-36bd8bc069b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  242k  100  242k    0     0  1412k      0 --:--:-- --:--:-- --:--:-- 1415k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/local/lib/python3.10/dist-packages/pyspark/jars/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJx9yuqmN7Lt",
        "outputId": "75de4453-7f87-44f7-b3d1-2c274e23a4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation-1.1.1.jar\n",
            "aircompressor-0.25.jar\n",
            "algebra_2.12-2.0.1.jar\n",
            "annotations-17.0.0.jar\n",
            "antlr4-runtime-4.9.3.jar\n",
            "antlr-runtime-3.5.2.jar\n",
            "aopalliance-repackaged-2.6.1.jar\n",
            "arpack-3.0.3.jar\n",
            "arpack_combined_all-0.1.jar\n",
            "arrow-format-12.0.1.jar\n",
            "arrow-memory-core-12.0.1.jar\n",
            "arrow-memory-netty-12.0.1.jar\n",
            "arrow-vector-12.0.1.jar\n",
            "audience-annotations-0.5.0.jar\n",
            "avro-1.11.2.jar\n",
            "avro-ipc-1.11.2.jar\n",
            "avro-mapred-1.11.2.jar\n",
            "blas-3.0.3.jar\n",
            "bonecp-0.8.0.RELEASE.jar\n",
            "breeze_2.12-2.1.0.jar\n",
            "breeze-macros_2.12-2.1.0.jar\n",
            "cats-kernel_2.12-2.1.1.jar\n",
            "chill_2.12-0.10.0.jar\n",
            "chill-java-0.10.0.jar\n",
            "commons-cli-1.5.0.jar\n",
            "commons-codec-1.16.0.jar\n",
            "commons-collections-3.2.2.jar\n",
            "commons-collections4-4.4.jar\n",
            "commons-compiler-3.1.9.jar\n",
            "commons-compress-1.23.0.jar\n",
            "commons-crypto-1.1.0.jar\n",
            "commons-dbcp-1.4.jar\n",
            "commons-io-2.13.0.jar\n",
            "commons-lang-2.6.jar\n",
            "commons-lang3-3.12.0.jar\n",
            "commons-logging-1.1.3.jar\n",
            "commons-math3-3.6.1.jar\n",
            "commons-pool-1.5.4.jar\n",
            "commons-text-1.10.0.jar\n",
            "compress-lzf-1.1.2.jar\n",
            "curator-client-2.13.0.jar\n",
            "curator-framework-2.13.0.jar\n",
            "curator-recipes-2.13.0.jar\n",
            "datanucleus-api-jdo-4.2.4.jar\n",
            "datanucleus-core-4.1.17.jar\n",
            "datanucleus-rdbms-4.1.19.jar\n",
            "datasketches-java-3.3.0.jar\n",
            "datasketches-memory-2.1.0.jar\n",
            "derby-10.14.2.0.jar\n",
            "dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "flatbuffers-java-1.12.0.jar\n",
            "graphframes-0.8.2-spark3.3.2-s_2.11.jar\n",
            "gson-2.2.4.jar\n",
            "guava-14.0.1.jar\n",
            "hadoop-client-api-3.3.4.jar\n",
            "hadoop-client-runtime-3.3.4.jar\n",
            "hadoop-shaded-guava-1.1.1.jar\n",
            "hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "HikariCP-2.5.1.jar\n",
            "hive-beeline-2.3.9.jar\n",
            "hive-cli-2.3.9.jar\n",
            "hive-common-2.3.9.jar\n",
            "hive-exec-2.3.9-core.jar\n",
            "hive-jdbc-2.3.9.jar\n",
            "hive-llap-common-2.3.9.jar\n",
            "hive-metastore-2.3.9.jar\n",
            "hive-serde-2.3.9.jar\n",
            "hive-service-rpc-3.1.3.jar\n",
            "hive-shims-0.23-2.3.9.jar\n",
            "hive-shims-2.3.9.jar\n",
            "hive-shims-common-2.3.9.jar\n",
            "hive-shims-scheduler-2.3.9.jar\n",
            "hive-storage-api-2.8.1.jar\n",
            "hk2-api-2.6.1.jar\n",
            "hk2-locator-2.6.1.jar\n",
            "hk2-utils-2.6.1.jar\n",
            "httpclient-4.5.14.jar\n",
            "httpcore-4.4.16.jar\n",
            "istack-commons-runtime-3.0.8.jar\n",
            "ivy-2.5.1.jar\n",
            "jackson-annotations-2.15.2.jar\n",
            "jackson-core-2.15.2.jar\n",
            "jackson-core-asl-1.9.13.jar\n",
            "jackson-databind-2.15.2.jar\n",
            "jackson-dataformat-yaml-2.15.2.jar\n",
            "jackson-datatype-jsr310-2.15.2.jar\n",
            "jackson-mapper-asl-1.9.13.jar\n",
            "jackson-module-scala_2.12-2.15.2.jar\n",
            "jakarta.annotation-api-1.3.5.jar\n",
            "jakarta.inject-2.6.1.jar\n",
            "jakarta.servlet-api-4.0.3.jar\n",
            "jakarta.validation-api-2.0.2.jar\n",
            "jakarta.ws.rs-api-2.1.6.jar\n",
            "jakarta.xml.bind-api-2.3.2.jar\n",
            "janino-3.1.9.jar\n",
            "javassist-3.29.2-GA.jar\n",
            "javax.jdo-3.2.0-m3.jar\n",
            "javolution-5.5.1.jar\n",
            "jaxb-runtime-2.3.2.jar\n",
            "jcl-over-slf4j-2.0.7.jar\n",
            "jdo-api-3.0.1.jar\n",
            "jersey-client-2.40.jar\n",
            "jersey-common-2.40.jar\n",
            "jersey-container-servlet-2.40.jar\n",
            "jersey-container-servlet-core-2.40.jar\n",
            "jersey-hk2-2.40.jar\n",
            "jersey-server-2.40.jar\n",
            "JLargeArrays-1.5.jar\n",
            "jline-2.14.6.jar\n",
            "joda-time-2.12.5.jar\n",
            "jodd-core-3.5.2.jar\n",
            "jpam-1.1.jar\n",
            "json-1.8.jar\n",
            "json4s-ast_2.12-3.7.0-M11.jar\n",
            "json4s-core_2.12-3.7.0-M11.jar\n",
            "json4s-jackson_2.12-3.7.0-M11.jar\n",
            "json4s-scalap_2.12-3.7.0-M11.jar\n",
            "jsr305-3.0.0.jar\n",
            "jta-1.1.jar\n",
            "JTransforms-3.1.jar\n",
            "jul-to-slf4j-2.0.7.jar\n",
            "kryo-shaded-4.0.2.jar\n",
            "kubernetes-client-6.7.2.jar\n",
            "kubernetes-client-api-6.7.2.jar\n",
            "kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "kubernetes-model-admissionregistration-6.7.2.jar\n",
            "kubernetes-model-apiextensions-6.7.2.jar\n",
            "kubernetes-model-apps-6.7.2.jar\n",
            "kubernetes-model-autoscaling-6.7.2.jar\n",
            "kubernetes-model-batch-6.7.2.jar\n",
            "kubernetes-model-certificates-6.7.2.jar\n",
            "kubernetes-model-common-6.7.2.jar\n",
            "kubernetes-model-coordination-6.7.2.jar\n",
            "kubernetes-model-core-6.7.2.jar\n",
            "kubernetes-model-discovery-6.7.2.jar\n",
            "kubernetes-model-events-6.7.2.jar\n",
            "kubernetes-model-extensions-6.7.2.jar\n",
            "kubernetes-model-flowcontrol-6.7.2.jar\n",
            "kubernetes-model-gatewayapi-6.7.2.jar\n",
            "kubernetes-model-metrics-6.7.2.jar\n",
            "kubernetes-model-networking-6.7.2.jar\n",
            "kubernetes-model-node-6.7.2.jar\n",
            "kubernetes-model-policy-6.7.2.jar\n",
            "kubernetes-model-rbac-6.7.2.jar\n",
            "kubernetes-model-resource-6.7.2.jar\n",
            "kubernetes-model-scheduling-6.7.2.jar\n",
            "kubernetes-model-storageclass-6.7.2.jar\n",
            "lapack-3.0.3.jar\n",
            "leveldbjni-all-1.8.jar\n",
            "libfb303-0.9.3.jar\n",
            "libthrift-0.12.0.jar\n",
            "log4j-1.2-api-2.20.0.jar\n",
            "log4j-api-2.20.0.jar\n",
            "log4j-core-2.20.0.jar\n",
            "log4j-slf4j2-impl-2.20.0.jar\n",
            "logging-interceptor-3.12.12.jar\n",
            "lz4-java-1.8.0.jar\n",
            "mesos-1.4.3-shaded-protobuf.jar\n",
            "metrics-core-4.2.19.jar\n",
            "metrics-graphite-4.2.19.jar\n",
            "metrics-jmx-4.2.19.jar\n",
            "metrics-json-4.2.19.jar\n",
            "metrics-jvm-4.2.19.jar\n",
            "minlog-1.3.0.jar\n",
            "netty-all-4.1.96.Final.jar\n",
            "netty-buffer-4.1.96.Final.jar\n",
            "netty-codec-4.1.96.Final.jar\n",
            "netty-codec-http2-4.1.96.Final.jar\n",
            "netty-codec-http-4.1.96.Final.jar\n",
            "netty-codec-socks-4.1.96.Final.jar\n",
            "netty-common-4.1.96.Final.jar\n",
            "netty-handler-4.1.96.Final.jar\n",
            "netty-handler-proxy-4.1.96.Final.jar\n",
            "netty-resolver-4.1.96.Final.jar\n",
            "netty-transport-4.1.96.Final.jar\n",
            "netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "objenesis-3.3.jar\n",
            "okhttp-3.12.12.jar\n",
            "okio-1.15.0.jar\n",
            "opencsv-2.3.jar\n",
            "orc-core-1.9.1-shaded-protobuf.jar\n",
            "orc-mapreduce-1.9.1-shaded-protobuf.jar\n",
            "orc-shims-1.9.1.jar\n",
            "oro-2.0.8.jar\n",
            "osgi-resource-locator-1.0.3.jar\n",
            "paranamer-2.8.jar\n",
            "parquet-column-1.13.1.jar\n",
            "parquet-common-1.13.1.jar\n",
            "parquet-encoding-1.13.1.jar\n",
            "parquet-format-structures-1.13.1.jar\n",
            "parquet-hadoop-1.13.1.jar\n",
            "parquet-jackson-1.13.1.jar\n",
            "pickle-1.3.jar\n",
            "py4j-0.10.9.7.jar\n",
            "RoaringBitmap-0.9.45.jar\n",
            "rocksdbjni-8.3.2.jar\n",
            "scala-collection-compat_2.12-2.7.0.jar\n",
            "scala-compiler-2.12.18.jar\n",
            "scala-library-2.12.18.jar\n",
            "scala-parser-combinators_2.12-2.3.0.jar\n",
            "scala-reflect-2.12.18.jar\n",
            "scala-xml_2.12-2.1.0.jar\n",
            "shims-0.9.45.jar\n",
            "slf4j-api-2.0.7.jar\n",
            "snakeyaml-2.0.jar\n",
            "snakeyaml-engine-2.6.jar\n",
            "snappy-java-1.1.10.3.jar\n",
            "spark-catalyst_2.12-3.5.0.jar\n",
            "spark-common-utils_2.12-3.5.0.jar\n",
            "spark-core_2.12-3.5.0.jar\n",
            "spark-graphx_2.12-3.5.0.jar\n",
            "spark-hive_2.12-3.5.0.jar\n",
            "spark-hive-thriftserver_2.12-3.5.0.jar\n",
            "spark-kubernetes_2.12-3.5.0.jar\n",
            "spark-kvstore_2.12-3.5.0.jar\n",
            "spark-launcher_2.12-3.5.0.jar\n",
            "spark-mesos_2.12-3.5.0.jar\n",
            "spark-mllib_2.12-3.5.0.jar\n",
            "spark-mllib-local_2.12-3.5.0.jar\n",
            "spark-network-common_2.12-3.5.0.jar\n",
            "spark-network-shuffle_2.12-3.5.0.jar\n",
            "spark-repl_2.12-3.5.0.jar\n",
            "spark-sketch_2.12-3.5.0.jar\n",
            "spark-sql_2.12-3.5.0.jar\n",
            "spark-sql-api_2.12-3.5.0.jar\n",
            "spark-streaming_2.12-3.5.0.jar\n",
            "spark-tags_2.12-3.5.0.jar\n",
            "spark-unsafe_2.12-3.5.0.jar\n",
            "spark-yarn_2.12-3.5.0.jar\n",
            "spire_2.12-0.17.0.jar\n",
            "spire-macros_2.12-0.17.0.jar\n",
            "spire-platform_2.12-0.17.0.jar\n",
            "spire-util_2.12-0.17.0.jar\n",
            "ST4-4.0.4.jar\n",
            "stax-api-1.0.1.jar\n",
            "stream-2.9.6.jar\n",
            "super-csv-2.2.0.jar\n",
            "threeten-extra-1.7.1.jar\n",
            "tink-1.9.0.jar\n",
            "transaction-api-1.1.jar\n",
            "univocity-parsers-2.9.1.jar\n",
            "xbean-asm9-shaded-4.23.jar\n",
            "xz-1.9.jar\n",
            "zjsonpatch-0.3.0.jar\n",
            "zookeeper-3.6.3.jar\n",
            "zookeeper-jute-3.6.3.jar\n",
            "zstd-jni-1.5.5-4.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Starting Spark with Libraries Loaded"
      ],
      "metadata": {
        "id": "VGIaDORNCi6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .config(\"spark.jars\", \"/usr/local/lib/python3.10/dist-packages/pyspark/jars/graphframes-0.8.2-spark3.3.2-s_2.11.jar\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)  # Property used to format output tables better\\\n"
      ],
      "metadata": {
        "id": "ar1W2F-fVd9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Dataset"
      ],
      "metadata": {
        "id": "jdylpyZXCovt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphframes import *\n",
        "from graphframes import GraphFrame"
      ],
      "metadata": {
        "id": "-HwAVZTUMIqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('PySpark Version :'+spark.version)\n",
        "print('PySpark Version :'+spark.sparkContext.version)\n"
      ],
      "metadata": {
        "id": "E59CQbZIRtuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318038ba-babd-431a-9b5c-7b42afb54db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Version :3.5.0\n",
            "PySpark Version :3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_rdd = spark.sparkContext.textFile(\"/content/soc-Epinions1.txt\").zipWithIndex()\n",
        "display(spark.createDataFrame(row_rdd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "cgilhGfArN94",
        "outputId": "0fffafc7-9eff-48da-f260-6e44f02b9e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+--------------------+---+\n",
              "|                  _1| _2|\n",
              "+--------------------+---+\n",
              "|# Directed graph ...|  0|\n",
              "|# Directed Epinio...|  1|\n",
              "|# Nodes: 75879 Ed...|  2|\n",
              "|# FromNodeId\\tToN...|  3|\n",
              "|                0\\t4|  4|\n",
              "|                0\\t5|  5|\n",
              "|                0\\t7|  6|\n",
              "|                0\\t8|  7|\n",
              "|                0\\t9|  8|\n",
              "|               0\\t10|  9|\n",
              "|               0\\t11| 10|\n",
              "|               0\\t12| 11|\n",
              "|               0\\t13| 12|\n",
              "|               0\\t14| 13|\n",
              "|               0\\t15| 14|\n",
              "|               0\\t16| 15|\n",
              "|               0\\t17| 16|\n",
              "|               0\\t18| 17|\n",
              "|               0\\t19| 18|\n",
              "|               0\\t20| 19|\n",
              "+--------------------+---+\n",
              "only showing top 20 rows"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>_1</th><th>_2</th></tr>\n",
              "<tr><td># Directed graph ...</td><td>0</td></tr>\n",
              "<tr><td># Directed Epinio...</td><td>1</td></tr>\n",
              "<tr><td># Nodes: 75879 Ed...</td><td>2</td></tr>\n",
              "<tr><td># FromNodeId\\tToN...</td><td>3</td></tr>\n",
              "<tr><td>0\\t4</td><td>4</td></tr>\n",
              "<tr><td>0\\t5</td><td>5</td></tr>\n",
              "<tr><td>0\\t7</td><td>6</td></tr>\n",
              "<tr><td>0\\t8</td><td>7</td></tr>\n",
              "<tr><td>0\\t9</td><td>8</td></tr>\n",
              "<tr><td>0\\t10</td><td>9</td></tr>\n",
              "<tr><td>0\\t11</td><td>10</td></tr>\n",
              "<tr><td>0\\t12</td><td>11</td></tr>\n",
              "<tr><td>0\\t13</td><td>12</td></tr>\n",
              "<tr><td>0\\t14</td><td>13</td></tr>\n",
              "<tr><td>0\\t15</td><td>14</td></tr>\n",
              "<tr><td>0\\t16</td><td>15</td></tr>\n",
              "<tr><td>0\\t17</td><td>16</td></tr>\n",
              "<tr><td>0\\t18</td><td>17</td></tr>\n",
              "<tr><td>0\\t19</td><td>18</td></tr>\n",
              "<tr><td>0\\t20</td><td>19</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_skip_rows = 3\n",
        "row_rdd = spark.sparkContext.textFile(\"/content/soc-Epinions1.txt\").zipWithIndex().filter(lambda row: row[1] >= n_skip_rows) \\\n",
        "    .map(lambda row: row[0])\n",
        "df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\"\\t\").csv(row_rdd)\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMbnPNerfVP",
        "outputId": "e246907c-cd90-49e9-fd49-7bec5312c08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+\n",
            "|# FromNodeId|ToNodeId|\n",
            "+------------+--------+\n",
            "|           0|       4|\n",
            "|           0|       5|\n",
            "|           0|       7|\n",
            "|           0|       8|\n",
            "|           0|       9|\n",
            "+------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_name = df.columns[0]\n",
        "data = df.withColumnRenamed(column_name, column_name[2:])\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmuMFTHls_5X",
        "outputId": "f359f8c8-6645-4477-e7d3-7faf10b9d7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FromNodeId: integer (nullable = true)\n",
            " |-- ToNodeId: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_QrjGj9tChH",
        "outputId": "551bd98e-9dbc-47c9-b76b-7252a8a3631f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+\n",
            "|FromNodeId|ToNodeId|\n",
            "+----------+--------+\n",
            "|         0|       4|\n",
            "|         0|       5|\n",
            "|         0|       7|\n",
            "|         0|       8|\n",
            "|         0|       9|\n",
            "+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vertices_FromNode = data.select(\"FromNodeId\").toDF(\"id\").distinct()\n",
        "vertices_ToNode = data.select(\"ToNodeId\").toDF(\"id\").distinct()\n",
        "vertices = vertices_FromNode.union(vertices_ToNode).distinct().sort(\"id\")\n",
        "vertices.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxU-dDErtFCE",
        "outputId": "bbccad3c-ea47-49ed-9246-9aefb58bc23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vertices.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFAiLD4CtHEU",
        "outputId": "333f83d8-cac1-4a28-dab6-3b03c5451d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75879"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges = data.select(\"FromNodeId\", \"ToNodeId\").toDF(\"src\", \"dst\")\n",
        "edges.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COGVSAi_tKcX",
        "outputId": "1a4eec39-4cc8-4f5a-d433-e03cb76dae3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "|src|dst|\n",
            "+---+---+\n",
            "|  0|  4|\n",
            "|  0|  5|\n",
            "|  0|  7|\n",
            "|  0|  8|\n",
            "|  0|  9|\n",
            "+---+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb956YrytMmL",
        "outputId": "7db12e13-9f74-432f-f1ba-07abde08094a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508837"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphframes import GraphFrame\n",
        "from pyspark.sql.functions import count, desc, sum\n",
        "\n",
        "epinionsGraph = GraphFrame(vertices, edges)\n",
        "epinionsGraph.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAMro-Z0tPK8",
        "outputId": "366ef526-d1d7-4d32-9b22-2400697a6bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphFrame(v:[id: int], e:[src: int, dst: int])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a. Find the top 5 nodes with the highest outdegree and find the count of the number of outgoing edges in each\n",
        "outDeg = epinionsGraph.outDegrees\n",
        "outDeg.orderBy(desc(\"outDegree\")).show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed_-DdbYtSLg",
        "outputId": "0f97011f-72b6-4cdd-dea0-090ecf8b1425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+\n",
            "|id   |outDegree|\n",
            "+-----+---------+\n",
            "|645  |1801     |\n",
            "|763  |1669     |\n",
            "|634  |1621     |\n",
            "|71399|1128     |\n",
            "|3924 |976      |\n",
            "+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# b. Find the top 5 nodes with the highest indegree and find the count of the number of incoming edges in each\n",
        "inDeg = epinionsGraph.inDegrees\n",
        "inDeg.orderBy(desc(\"inDegree\")).show(5, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7JtreA4t-3p",
        "outputId": "c28ed260-a02e-4653-91aa-6fdb66d43868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "|id |inDegree|\n",
            "+---+--------+\n",
            "|18 |3035    |\n",
            "|143|1521    |\n",
            "|737|1317    |\n",
            "|790|1284    |\n",
            "|136|1180    |\n",
            "+---+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c. Calculate PageRank for each of the nodes and output the top 5 nodes with the highest PageRank values. You are free to define any suitable parameters.\n",
        "ranks = epinionsGraph.pageRank(resetProbability=0.15, maxIter=10)"
      ],
      "metadata": {
        "id": "5cwHjBFqvWtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks.vertices.orderBy(desc(\"pagerank\")).select(\"id\", \"pagerank\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrYjlCIDvYmj",
        "outputId": "5dfe91bf-f1c0-455d-b590-faf508d54cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+\n",
            "|  id|          pagerank|\n",
            "+----+------------------+\n",
            "|  18|345.13733694778057|\n",
            "| 737|240.25396712965642|\n",
            "| 118|162.02085699786338|\n",
            "|1719| 158.8534560750275|\n",
            "| 136|151.67122319877475|\n",
            "+----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d. Run the connected components algorithm on it and find the top 5 components with the largest number of nodes.\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/checkpoints\")"
      ],
      "metadata": {
        "id": "yl6RyTd6vaVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset is a directed Graph we should use the stronglyConnectedComponents()\n",
        "scc = epinionsGraph.stronglyConnectedComponents(maxIter=3)\n",
        "scc.groupBy(\"component\").agg(count('id').alias('count')).orderBy(desc(\"count\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jopwM_IvcbD",
        "outputId": "a2d04a01-f462-41fd-9f2d-d2137f8a4872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|component|count|\n",
            "+---------+-----+\n",
            "|        0|32223|\n",
            "|    47210|   15|\n",
            "|    33367|    9|\n",
            "|      515|    9|\n",
            "|    49556|    8|\n",
            "+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# e. Run the triangle counts algorithm on each of the vertices and output the top 5 vertices with the largest triangle count. In case of ties, you can randomly select the top 5 vertices.\n",
        "tc = epinionsGraph.triangleCount()\n",
        "tc.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHGG_Gfk4Pg-",
        "outputId": "f36cf8e8-b8fa-4ee6-b320-e86b5068d51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|count| id|\n",
            "+-----+---+\n",
            "|16511|  1|\n",
            "|  302|  3|\n",
            "| 4854|  5|\n",
            "| 2716|  4|\n",
            "| 3885|  2|\n",
            "+-----+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc.orderBy(desc(\"count\")).show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbzMxPyG4Rup",
        "outputId": "e1600a89-d70b-4747-bb54-10ebb75fc86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|count|id |\n",
            "+-----+---+\n",
            "|48674|645|\n",
            "|47203|18 |\n",
            "|25817|27 |\n",
            "|25230|634|\n",
            "|24752|44 |\n",
            "+-----+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of triangles    1624481\n",
        "# 1624481 * 3 = 4873443 - A triangle it is added thrice for each of the three vertices\n",
        "print(1624481 * 3)\n",
        "tc.agg(sum('count').alias('totalCount')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMRdQN824bXt",
        "outputId": "ce7f0ad9-7ed0-40b2-9723-e748e6a7cae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4873443\n",
            "+----------+\n",
            "|totalCount|\n",
            "+----------+\n",
            "|   4873443|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}